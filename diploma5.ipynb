{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T16:36:35.552666Z",
     "start_time": "2025-02-06T16:36:33.396586Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import logging\n",
    "# В utils мы реализуем дополнительные функции для визуализации процессора обучения\n",
    "import utils\n",
    "# Настраиваем логирование\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# Настраиваем стиль графиков\n",
    "sns.set_style('darkgrid')\n",
    "# Проверяем подходит ли наша GPU для tensorflow\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:36:35.560168Z",
     "start_time": "2025-02-06T16:36:35.555620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Рисует график обучения\n",
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the training and validation data\n",
    "    tacc = tr_data.history['accuracy']\n",
    "    tloss = tr_data.history['loss']\n",
    "    vacc = tr_data.history['val_accuracy']\n",
    "    vloss = tr_data.history['val_loss']\n",
    "    Epoch_count = len(tacc) + start_epoch\n",
    "    Epochs = []\n",
    "    for i in range (start_epoch, Epoch_count):\n",
    "        Epochs.append(i + 1)\n",
    "    index_loss  = np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest  = vloss[index_loss]\n",
    "    index_acc   = np.argmax(vacc)\n",
    "    acc_highest = vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label = 'Лучшая эпоха= '+ str(index_loss + 1 + start_epoch)\n",
    "    vc_label = 'Лучшая эпоха= '+ str(index_acc  + 1 + start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols = 2, figsize = (20,8))\n",
    "    axes[0].plot (Epochs,tloss, 'r', label = 'Потери при обучении')\n",
    "    axes[0].plot (Epochs,vloss,'g',label='Потери при валидации' )\n",
    "    axes[0].scatter (index_loss + 1 + start_epoch,val_lowest, s = 150, c = 'blue', label = sc_label)\n",
    "    axes[0].set_title('Потери при валидации и обучении')\n",
    "    axes[0].set_xlabel('Эпохи')\n",
    "    axes[0].set_ylabel('Потери')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r', label = 'Точность при обучении')\n",
    "    axes[1].plot (Epochs,vacc,'g', label = 'Точность при валидации')\n",
    "    axes[1].scatter(index_acc + 1 + start_epoch, acc_highest, s = 150, c = 'blue', label = vc_label)\n",
    "    axes[1].set_title  ('Точность при валидации и обучении')\n",
    "    axes[1].set_xlabel ('Эпохи')\n",
    "    axes[1].set_ylabel ('Точность')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    plt.show()\n",
    "# Создаем data_frame, в котором название папки является меткой класса изображений (коты и собаки в нашем случае)\n",
    "# Каждому элементу data_frame будет присвоена метка (DX) и название файла (image)\n",
    "# Функция возвращает объект frame\n",
    "def load_data_frame(sdir):\n",
    "    classlist = os.listdir(sdir)\n",
    "    classlist.remove('.DS_Store')\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(sdir, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath = os.path.join(classpath, f)\n",
    "            filepaths.append( fpath.replace('\\\\', '/') )\n",
    "            labels.append(klass)\n",
    "\n",
    "    Fseries=pd.Series( filepaths, name = 'image' )\n",
    "    Lseries=pd.Series(labels, name = 'dx')\n",
    "    return pd.concat([Fseries, Lseries], axis=1)"
   ],
   "id": "19ca55119dd955f9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:44:20.075301Z",
     "start_time": "2025-02-06T16:44:20.030001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Размер картинки для подачи в модели\n",
    "height   = 224\n",
    "width    = 224\n",
    "channels = 3\n",
    "\n",
    "# Размер пачки для обучения\n",
    "batch_size = 20\n",
    "# Размер пачки для валидации\n",
    "test_batch_size = 50\n",
    "\n",
    "# Инициализаци рандом: None - всегда рандом, Число - повторяемый рандом\n",
    "my_random = 100\n",
    "\n",
    "# Загружаем сгенерированные картинки (картинка должны лежать по папкам с названием их DX)\n",
    "df2 = load_data_frame (\"/Users/davemag9/Desktop/Diploma/archive1/Indian Food Images/Indian Food Images\")\n",
    "\n",
    "# Разделяем выборку на обучающую, тестовую и валидационную (случайным образом)\n",
    "train_df, test_df = train_test_split (df2, train_size= .9, shuffle = True, random_state = my_random)\n",
    "valid_df, test_df = train_test_split (test_df, train_size= .5, shuffle = True, random_state = my_random)\n",
    "\n",
    "# Задаем параметры входящей картинки\n",
    "img_shape = (height, width, channels)\n",
    "img_size  = (height, width)\n",
    "length    = len(test_df)\n",
    "\n",
    "# выводим найденное число n\n",
    "test_steps = int(length/test_batch_size)\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "\n",
    "# C помощью ImageDataGenerator () можно аугментировать изображения прямо во время обучения, но аугментация — это отдельная тема\n",
    "trgen = ImageDataGenerator()\n",
    "\n",
    "# Генератор для тестовой выборки\n",
    "tvgen = ImageDataGenerator()\n",
    "\n",
    "# Выборка для обучения модели\n",
    "train_gen = trgen.flow_from_dataframe ( train_df, directory = None, x_col = \"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Выборка для тестирования сети после обучения\n",
    "test_gen = tvgen.flow_from_dataframe ( test_df, directory = None, x_col= \"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "# Выборка для тестирования сети во время обучения\n",
    "valid_gen = tvgen.flow_from_dataframe ( valid_df, directory = None, x_col=\"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
    "                                    color_mode='rgb', shuffle = True, batch_size = batch_size)"
   ],
   "id": "22285145e17cd7cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch size:  50   test steps:  4\n",
      "Found 3600 validated image filenames belonging to 80 classes.\n",
      "Found 200 validated image filenames belonging to 72 classes.\n",
      "Found 200 validated image filenames belonging to 75 classes.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:36:36.062197Z",
     "start_time": "2025-02-06T16:36:35.686853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получаем метки классов\n",
    "classes     = list (train_gen.class_indices.keys())\n",
    "class_count = len(classes)\n",
    "train_steps = np.ceil(len(train_gen.labels)/batch_size)\n",
    "# Задаем имя модели\n",
    "model_name = 'EfficientNetB0'\n",
    "# Генерируем экземпляр модели EfficientNetB0\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top = False, weights = \"imagenet\", input_shape = img_shape, pooling = 'max')\n",
    "# Создаем выходной слой\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001 )(x)\n",
    "x = Dense(256,\n",
    "          kernel_regularizer=regularizers.l2(0.016),  # Corrected `l2`\n",
    "          activity_regularizer=regularizers.l1(0.006),\n",
    "          bias_regularizer=regularizers.l1(0.006),\n",
    "          activation='relu')(x)\n",
    "x = Dropout(rate = .45, seed = my_random)(x)\n",
    "#Создаем выходной полносвязный слой и присоединяем его к предыдущим слоям (количество нейронов совпадает с количеством классов\n",
    "output = Dense(class_count, activation = 'softmax')(x)\n",
    "# Собираем модель вместе\n",
    "model = Model(inputs = base_model.input, outputs = output)\n",
    "# Компилируем модель\n",
    "model.compile(optimizer=Adamax(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "eef3941d51b36cc1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T16:40:26.250190Z",
     "start_time": "2025-02-06T16:36:36.068293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Задаем параметры обучения\n",
    "epochs        = 15 # Количество эпох\n",
    "patience      = 1 # количество эпох, в течение которых необходимо отрегулировать lr, если отслеживаемое значение не улучшится\n",
    "stop_patience = 6 # количество эпох ожидания перед остановкой обучения, если отслеживаемое значение не улучшится\n",
    "threshold     = .9\n",
    "factor        = .5\n",
    "dwell         = True # если True и отслеживаемая метрика не улучшаются по сравнению с текущей эпохой, возвращают веса модели к весам предыдущей эпохи.\n",
    "freeze        = False #\n",
    "ask_epoch     = 10 # количество эпох, которые нужно выполнить, прежде чем спросить, хотите ли вы остановить обучение\n",
    "batches       = train_steps\n",
    "\n",
    "# utils.LRA реализует вывод информации прямо в процессе обучения\n",
    "#  Об этом стоит рассказать подробнее, но это тема для отдельной статьи\n",
    "callbacks = [utils.LRA(model = model,\n",
    "                       base_model = base_model,\n",
    "                       patience=patience,\n",
    "                       stop_patience = stop_patience,\n",
    "                       threshold = threshold,\n",
    "                       factor = factor,\n",
    "                       dwell = dwell,\n",
    "                       batches = batches,\n",
    "                       initial_epoch = 0,\n",
    "                       epochs = epochs,\n",
    "                       ask_epoch = ask_epoch )]\n",
    "# Запускаем обучение модели и сохраняем историю обучения\n",
    "history = model.fit (x = train_gen,  epochs = epochs, verbose = 0, callbacks = callbacks,  validation_data = valid_gen, validation_steps = None,  shuffle = False,  initial_epoch = 0)\n",
    "\n",
    "# Рисуем график обучения и выводим\n",
    "tr_plot(history,0)\n",
    "# Проверяем точность модели на тестовой выборке и выводим результат тестирования\n",
    "save_dir = './'\n",
    "subject = 'Cat and Dog'\n",
    "\n",
    "acc = model.evaluate( test_gen, batch_size = test_batch_size, verbose = 1, steps=test_steps, return_dict = False)[1]*100\n",
    "msg = f'accuracy on the test set is {acc:5.2f} %'\n",
    "utils.print_in_color(msg, (0,255,0),(55,65,80))\n",
    "\n",
    "# Сохраняем модель в файл, его потом можно загрузить и использовать без обучения для классификации изображений\n",
    "save_id   = str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
    "save_loc  = os.path.join(save_dir, save_id)\n",
    "model.save(save_loc)\n",
    "generator = train_gen\n",
    "scale     = 1\n",
    "result    = utils.saver(save_dir, model, model_name, subject, acc, img_size, scale,  generator)"
   ],
   "id": "ccd5074a6e5bb1b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;244;252;3;48;2;55;65;80minitializing callback starting train with base_model trainable\n",
      "\u001B[0m\n",
      "\u001B[38;2;244;252;3;48;2;55;65;80m Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  Duration\n",
      "\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davemag9/Desktop/Diploma/venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    processing batch 179  of 180.0 accuracy=    1.333  loss: 13.39286 \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 75), output.shape=(None, 80)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 26\u001B[0m\n\u001B[1;32m     14\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [utils\u001B[38;5;241m.\u001B[39mLRA(model \u001B[38;5;241m=\u001B[39m model,\n\u001B[1;32m     15\u001B[0m                        base_model \u001B[38;5;241m=\u001B[39m base_model,\n\u001B[1;32m     16\u001B[0m                        patience\u001B[38;5;241m=\u001B[39mpatience,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m                        epochs \u001B[38;5;241m=\u001B[39m epochs,\n\u001B[1;32m     24\u001B[0m                        ask_epoch \u001B[38;5;241m=\u001B[39m ask_epoch )]\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Запускаем обучение модели и сохраняем историю обучения\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvalid_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Рисуем график обучения и выводим\u001B[39;00m\n\u001B[1;32m     29\u001B[0m tr_plot(history,\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/Diploma/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Desktop/Diploma/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:660\u001B[0m, in \u001B[0;36mcategorical_crossentropy\u001B[0;34m(target, output, from_logits, axis)\u001B[0m\n\u001B[1;32m    658\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e1, e2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape, output\u001B[38;5;241m.\u001B[39mshape):\n\u001B[1;32m    659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e1 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e2 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e1 \u001B[38;5;241m!=\u001B[39m e2:\n\u001B[0;32m--> 660\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    661\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArguments `target` and `output` must have the same shape. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    662\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    663\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, output.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    664\u001B[0m         )\n\u001B[1;32m    666\u001B[0m output, from_logits \u001B[38;5;241m=\u001B[39m _get_logits(\n\u001B[1;32m    667\u001B[0m     output, from_logits, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSoftmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    668\u001B[0m )\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m from_logits:\n",
      "\u001B[0;31mValueError\u001B[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 75), output.shape=(None, 80)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9ebf2f706669dc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
